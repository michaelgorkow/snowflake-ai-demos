{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "53535a9c-9d8b-411a-9ce3-bf7df96f23f0",
      "metadata": {
        "collapsed": false,
        "name": "IMPORTS",
        "codeCollapsed": true
      },
      "source": "# Imports"
    },
    {
      "id": "d65216bb-a7a5-4529-beb2-0511e77db9d9",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PACKAGE_INSTALL",
        "title": "PACKAGE_INSTALL"
      },
      "source": "# Make sure to restart kernel after package installation\n%pip install --q -e ../ ipywidgets",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3775908f-ca36-4846-8f38-5adca39217f2",
      "metadata": {
        "language": "python",
        "name": "IMPORTS_1",
        "title": "IMPORTS_1"
      },
      "outputs": [],
      "source": "# Import python packages\nimport pandas as pd\nimport json\nfrom datetime import date\n\n# ML packages\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# Snowpark\nfrom snowflake.snowpark import functions as F\nfrom snowflake.snowpark import Window\nfrom snowflake.snowpark.context import get_active_session\n\n# Experiment Tracking API\nfrom snowflake.ml.experiment.experiment_tracking import ExperimentTracking\nfrom snowflake.ml.experiment.callback.xgboost import SnowflakeXgboostCallback\n\n# Feature Store API\nfrom snowflake.ml.feature_store import FeatureStore, CreationMode, Entity, FeatureView, OnlineConfig\n\n# Model Registry API\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model.model_signature import infer_signature\nfrom snowflake.ml.monitoring.entities.model_monitor_config import ModelMonitorConfig, ModelMonitorSourceConfig\n\n# Demo-specific functions\nimport demo_functions\n\nsession = get_active_session()\n\ndatabase = 'AI_DEMOS'\nschema = 'IOT_PREDICTIVE_MAINTENANCE'\nwarehouse = 'AI_WH'\ncurrent_date = date.today().isoformat()\n\nsession.use_database(database)\n\n# Setup demo\ndemo_functions.setup(session, schema)"
    },
    {
      "cell_type": "markdown",
      "id": "f4b13c9f-3a1a-4380-ae60-85fee818286a",
      "metadata": {
        "collapsed": false,
        "name": "SETUP_MLOPS_FEATURES",
        "codeCollapsed": true
      },
      "source": "# 1 - Setup Feature Store and Model Registry"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5323ef57-1cf8-4dd7-b4cc-d1f8fde01ac9",
      "metadata": {
        "language": "python",
        "name": "SETUP_MLOPS_FEATURES_1"
      },
      "outputs": [],
      "source": "# Create a Feature Store\nmy_feature_store = FeatureStore(\n    session=session,\n    database=database,\n    name=f\"{schema}_FEATURE_STORE\",\n    default_warehouse=warehouse,\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n)\n\n# Create a Model Registry\nmy_model_registry = Registry(\n    session=session, \n    database_name=database, \n    schema_name=f'{schema}_MODEL_REGISTRY', \n    options={'enable_monitoring':True}\n)"
    },
    {
      "cell_type": "markdown",
      "id": "6c92c485-9703-4c6c-a68b-ad059ad74269",
      "metadata": {
        "collapsed": false,
        "name": "DATA_EXPLORATION",
        "codeCollapsed": true
      },
      "source": "# 2 - Explore Data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a4bf0c-2fa7-42f8-8187-770024d88df5",
      "metadata": {
        "language": "python",
        "name": "DATA_EXPLORATION_1",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "sensor_data = session.table(f'{database}.{schema}.MACHINE_SENSORS')\nprint('Sensor Data:')\ndisplay(sensor_data.limit(5))\n\nmachine_failures = session.table(f'{database}.{schema}.MACHINE_FAILURES')\nprint('Machine Failures:')\ndisplay(machine_failures.limit(5))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ac57a73-5fa0-4636-a6fe-5b69287e0d0b",
      "metadata": {
        "language": "python",
        "name": "DATA_EXPLORATION_2"
      },
      "outputs": [],
      "source": "daily_sensor_data = (\n    # daily aggregration of sensor values \n    sensor_data\n        .with_column('DATE', F.date_trunc('DAY','SENSOR_TIMESTAMP').cast('date'))\n        .group_by('MACHINE_ID','DATE')\n        .agg(\n            F.avg('SENSOR_1').alias('SENSOR_1_DAILY_AVERAGE'),\n            F.avg('SENSOR_2').alias('SENSOR_2_DAILY_AVERAGE'),\n            F.avg('SENSOR_3').alias('SENSOR_3_DAILY_AVERAGE')\n        )\n)\n\ndisplay(daily_sensor_data.limit(5))"
    },
    {
      "id": "b5b732d8-763d-40a0-a711-c6c9b3210997",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Visualize Data"
    },
    {
      "id": "5fecf82d-27e6-435a-908e-7ab1dea0bbce",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "BUILTIN_VISUALS",
        "title": "BUILTIN_VISUALS"
      },
      "source": "# use built-in visualizations\ndaily_sensor_data.filter(F.col('MACHINE_ID') == 'MACHINE_0000')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67a44d31-cfc4-4d5f-b075-5cff364df3b5",
      "metadata": {
        "language": "python",
        "name": "DATA_EXPLORATION_3"
      },
      "outputs": [],
      "source": "viz_df = (\n    daily_sensor_data.join(machine_failures, how='left', on=['MACHINE_ID','DATE'])\n        .order_by('MACHINE_ID','DATE')\n        .to_pandas()\n)\n\nviz_df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648dd4af-7370-457f-a3e9-93d0a3e29861",
      "metadata": {
        "language": "python",
        "name": "DATA_EXPLORATION_4"
      },
      "outputs": [],
      "source": "# Use plotly to visualize machine data\ndemo_functions.plot_machine_data(viz_df, 'MACHINE_0000')"
    },
    {
      "cell_type": "markdown",
      "id": "dedb287b-f81e-4f1a-a354-71a81bdf058b",
      "metadata": {
        "collapsed": false,
        "name": "FEATURE_ENGINEERING",
        "codeCollapsed": true
      },
      "source": "# 3 - Feature Engineering"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c993a123-1fc8-4737-ad23-0973b6884ffc",
      "metadata": {
        "language": "python",
        "name": "FEATURE_ENGINEERING_1"
      },
      "outputs": [],
      "source": "n_lags = 3\n\nlag_features = (\n    daily_sensor_data.analytics.compute_lag(\n        cols=['SENSOR_1_DAILY_AVERAGE','SENSOR_2_DAILY_AVERAGE','SENSOR_3_DAILY_AVERAGE'],\n        lags=list(range(1,n_lags+1)),\n        order_by=[\"DATE\"],\n        group_by=[\"MACHINE_ID\"]\n    )\n    .drop(['SENSOR_1_DAILY_AVERAGE','SENSOR_2_DAILY_AVERAGE','SENSOR_3_DAILY_AVERAGE'])\n)\n\ndisplay(lag_features.limit(10))"
    },
    {
      "cell_type": "markdown",
      "id": "e7a0a507-2ee0-45da-91c3-28d22cb7d5a9",
      "metadata": {
        "collapsed": false,
        "name": "REGISTER_FEATURES",
        "codeCollapsed": true
      },
      "source": "# 4 - Register Features"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f795933-442d-4daa-ada7-ad40be29b857",
      "metadata": {
        "language": "python",
        "name": "REGISTER_FEATURES_1"
      },
      "outputs": [],
      "source": "# Create Entity\nmachine_entity = Entity(\n    name=\"MACHINE\",\n    join_keys=[\"MACHINE_ID\"],\n    desc=\"Unique Machine ID\"\n)\n\n# Register Entity\nmy_feature_store.register_entity(machine_entity)\n\n# Create Feature View\nlag_features_fv = FeatureView(\n    name='MACHINE_SENSORS_LAG_FEATURES',\n    entities=[machine_entity],\n    feature_df=lag_features,\n    timestamp_col='DATE',\n    refresh_freq='1 minute',\n    refresh_mode='INCREMENTAL',\n    online_config=OnlineConfig(enable=False),\n    desc='Lag Features for Machine Sensors'\n)\n\n# Register Feature View\nlag_features_fv = my_feature_store.register_feature_view(\n    feature_view=lag_features_fv,\n    version='1',\n    overwrite=True\n)"
    },
    {
      "cell_type": "markdown",
      "id": "971a8544-1c56-4287-971c-230f2ed09341",
      "metadata": {
        "collapsed": false,
        "name": "TRAINING_DATASET",
        "codeCollapsed": true
      },
      "source": "# 5 - Generate Training Dataset "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf518201-b570-4a0f-828c-6a3075ff35b8",
      "metadata": {
        "language": "python",
        "name": "TRAINING_DATASET_1"
      },
      "outputs": [],
      "source": "def generate_training_dataset(session, feature_store, training_start_date, training_end_date):\n    # Get machines and timestamps\n    machines_df = (\n        session.table(f'{database}.{schema}.MACHINE_SENSORS')\n            .with_column('DATE', F.date_trunc('DAY','SENSOR_TIMESTAMP').cast('date'))\n            .filter(F.col('DATE').between(training_start_date, training_end_date))\n            .select('MACHINE_ID','DATE')\n            .distinct()\n    )\n    \n    # Get machine failures and offset by 1 day\n    machine_failures = (\n        session.table(f'{database}.{schema}.MACHINE_FAILURES')\n            .with_column('DATE', F.date_add(F.col('DATE'), F.lit(-1)))\n            .rename({'FAILURE':'FAILURE_IN_1_DAY'})\n    )\n    \n    # Create Spine DataFrame\n    spine_df = machines_df.join(machine_failures, how='left', on=['MACHINE_ID','DATE']).order_by('MACHINE_ID','DATE').fillna(0, subset=['FAILURE_IN_1_DAY'])\n    print('Created Spine DataFrame:')\n    display(spine_df.limit(10))\n\n    # Retrieve Features\n    print('Generating Dataset ...')\n    training_dataset = feature_store.generate_dataset(\n        name=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_DATASET',\n        spine_df=spine_df,\n        features=[lag_features_fv],\n        spine_timestamp_col='DATE',\n        spine_label_cols=['FAILURE_IN_1_DAY'],\n        desc='Training dataset to predict machine failures.'\n    )\n\n    # View Training Data\n    training_dataset_df = training_dataset.read.to_snowpark_dataframe()\n    print('Created Dataset:')\n    display(training_dataset_df.limit(10).to_pandas())\n    return training_dataset_df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb4c5d5-b9ae-4279-ab21-78a7e3039640",
      "metadata": {
        "language": "python",
        "name": "TRAINING_DATASET_2"
      },
      "outputs": [],
      "source": "training_start_date = '2025-01-04'\ntraining_end_date = '2025-04-01'\n\ntraining_dataset_df = generate_training_dataset(session, my_feature_store, training_start_date, training_end_date)"
    },
    {
      "cell_type": "markdown",
      "id": "9ae540c3-bfcc-4c8d-8c26-d6a8d313a186",
      "metadata": {
        "collapsed": false,
        "name": "MODEL_TRAINING",
        "codeCollapsed": true
      },
      "source": "# 6 - Train Model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0912e6b4-2cfa-4f91-8390-2d95d40e87e7",
      "metadata": {
        "language": "python",
        "name": "MODEL_TRAINING_1"
      },
      "outputs": [],
      "source": "def train_models(train_df, test_df, experiment_name):\n    train_df = train_df.to_pandas()\n    test_df = test_df.to_pandas()\n    \n    # Define target and features\n    target_column = 'FAILURE_IN_1_DAY'\n    unused_columns = [target_column,'MACHINE_ID','DATE']\n    feature_columns = list(train_df.drop(unused_columns, axis=1).columns)\n    \n    X_train = train_df[feature_columns]\n    y_train = train_df[target_column]\n    \n    X_test = test_df[feature_columns]\n    y_test = test_df[target_column]\n\n    # Setup Experiment Tracking\n    exp = ExperimentTracking(session=session)\n    exp.set_experiment(experiment_name)\n    callback = SnowflakeXgboostCallback(exp, log_every_n_epochs=2, log_model=False)\n    \n    # Define models\n    xgb_model = xgb.XGBClassifier(\n        tree_method=\"hist\", \n        callbacks=[callback], \n        eval_metric='aucpr',\n        early_stopping_rounds=2,\n        n_estimators=10\n    )\n\n    logreg_model = LogisticRegression(solver='liblinear', random_state=42) \n\n    training_results = {}\n    training_results['feature_columns'] = feature_columns\n    training_results['target_column'] = target_column\n    training_results['xgboost'] = {'model':None, 'metrics':None}\n    training_results['logisticregression'] = {'model':None, 'metrics':None}\n\n    # XGBoost Model\n    with exp.start_run(run_name='XGBoost_Classifier'):\n        xgb_model = xgb_model.fit(\n            X_train, \n            y_train, \n            eval_set=[(X_test, y_test)], \n            verbose=0\n        )\n        # Evaluate model on test data\n        y_pred = xgb_model.predict(X_test)\n        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=0.0)\n        metrics = {\n            \"precision\": precision, \n            \"recall\": recall,\n            \"f1\":f1\n        }\n        exp.log_metrics(metrics)\n        training_results['xgboost']['model'] = xgb_model\n        training_results['xgboost']['metrics'] = metrics\n\n    # Logistic Regression Model\n    with exp.start_run(run_name='Logistic_Regression'):\n        logreg_model.fit(X_train, y_train)\n        \n        # Evaluate model on test data\n        y_pred = logreg_model.predict(X_test)\n        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=0.0)\n\n        metrics = {\n            \"precision\": precision, \n            \"recall\": recall,\n            \"f1\": f1\n        }\n        exp.log_metrics(metrics)\n        training_results['logisticregression']['model'] = logreg_model\n        training_results['logisticregression']['metrics'] = metrics\n    return training_results"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2558bee6-bebe-4877-a488-da13839d88a2",
      "metadata": {
        "language": "python",
        "name": "MODEL_TRAINING_2"
      },
      "outputs": [],
      "source": "train_dataset_df = training_dataset_df.filter(F.col('DATE').between('2025-01-04','2025-02-28'))\ntest_datatset_df = training_dataset_df.filter(F.col('DATE').between('2025-03-01','2025-04-01'))\n\ntraining_results = train_models(train_dataset_df, test_datatset_df, experiment_name='PREDICTIVE_MAINTENANCE_MODELS')\n\n# Retrieve model results\nfeature_columns = training_results['feature_columns']\ntarget_column = training_results['target_column']\nxgb_model = training_results['xgboost']['model']\nmetrics = training_results['xgboost']['metrics']"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac75537-3165-435f-ac53-9659c1a1818b",
      "metadata": {
        "language": "python",
        "name": "MODEL_TRAINING_3"
      },
      "outputs": [],
      "source": "importance_df = pd.DataFrame({\n    'feature': xgb_model.get_booster().feature_names,\n    'importance': xgb_model.feature_importances_\n}).sort_values(by='importance', ascending=True)\n\nplotfig = importance_df.plot.barh(x='feature',y='importance', figsize=(4,4))"
    },
    {
      "cell_type": "markdown",
      "id": "7e71888e-e005-44a7-97f1-9f6e049f7418",
      "metadata": {
        "collapsed": false,
        "name": "REGISTER_MODEL",
        "codeCollapsed": true
      },
      "source": "# 7 - Register Model to Model Registry"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02c51c3d-982a-40d9-ab1b-11c41acbc9d8",
      "metadata": {
        "language": "python",
        "name": "REGISTER_MODEL_1",
        "title": "REGISTER_MODEL_1"
      },
      "outputs": [],
      "source": "# Infer the Model signature from training data\nsignature = infer_signature(\n    input_data=train_dataset_df.select(feature_columns).limit(100),\n    output_data=train_dataset_df.select(target_column).rename({'FAILURE_IN_1_DAY':'FAILURE_IN_1_DAY_PREDICTION'}).limit(100)\n)\n\n# Register model\nregistered_model = my_model_registry.log_model(\n    xgb_model,\n    model_name=\"PREDICTIVE_MAINTENANCE_MODEL\",\n    version_name='V1',\n    metrics=metrics,\n    comment=\"Model trained using XGBoost to predict machine failures\",\n    conda_dependencies=['xgboost'],\n    signatures={'predict':signature},\n    sample_input_data=training_dataset_df.select(feature_columns).limit(100),\n    options={\"relax_version\": True, \"enable_explainability\": False},\n    target_platforms=['WAREHOUSE','SNOWPARK_CONTAINER_SERVICES']\n)"
    },
    {
      "id": "13c06aca-036f-4ddb-80f9-0bad853f2750",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "REGISTER_MODEL_2",
        "title": "REGISTER_MODEL_2"
      },
      "source": "# View the registered model\nregistered_model",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "0a8ff5af-ca75-48ea-9d02-f8e7df1db908",
      "metadata": {
        "collapsed": false,
        "name": "MODEL_TO_PRODUCTION",
        "codeCollapsed": true
      },
      "source": "# 8 - Set Model to Production"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c90dbe-69d9-4602-b113-907dd679939e",
      "metadata": {
        "language": "python",
        "name": "MODEL_TO_PRODUCTION_1",
        "title": "MODEL_TO_PRODUCTION_1"
      },
      "outputs": [],
      "source": "# Set alias for model\nregistered_model.set_alias('PRODUCTION')\n\n# Retrieve the production model in your pipelines like this\nproduction_model = my_model_registry.get_model('PREDICTIVE_MAINTENANCE_MODEL').version('PRODUCTION')"
    },
    {
      "id": "7543cc8a-934c-4518-98aa-a30d0ce0caae",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "MODEL_TO_PRODUCTION_2",
        "title": "MODEL_TO_PRODUCTION_2"
      },
      "source": "# Query the model lineage to retrieve required feature views\nfeatureviews = production_model.lineage(direction='upstream')[0].lineage(domain_filter=['feature_view'], direction='upstream')\nfor featureview in featureviews:\n    print(f'Feature View Name: {featureview.name}')\n    print('Feature Names:')\n    for feature in featureview.feature_names:\n        print(feature)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f5297e91-2876-4eb5-9f99-2971bb317a8e",
      "metadata": {
        "collapsed": false,
        "name": "TEST_MODEL",
        "codeCollapsed": true
      },
      "source": "# 9 - Test Model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96455d86-6fd8-4fd5-8f6b-709f9018e464",
      "metadata": {
        "language": "python",
        "name": "TEST_MODEL_1"
      },
      "outputs": [],
      "source": "baseline_predictions = production_model.run(test_datatset_df, function_name='predict').cache_result()\ndisplay(baseline_predictions.limit(10))"
    },
    {
      "cell_type": "markdown",
      "id": "81a6e12a-393a-4269-acc8-daedde164163",
      "metadata": {
        "collapsed": false,
        "name": "MODEL_MONITORING",
        "codeCollapsed": true
      },
      "source": "# 10 - Model Monitoring"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329ab042-f0a8-4119-beee-6e42c729383e",
      "metadata": {
        "language": "python",
        "name": "MODEL_MONITORING_1"
      },
      "outputs": [],
      "source": "# Generate baseline predictions\nbaseline_predictions.write.save_as_table(f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_BASELINE_V1', mode='overwrite')\nbaseline_predictions.write.save_as_table(f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_SOURCE_V1', mode='overwrite')\n\n# Create model monitor\nsource_config = ModelMonitorSourceConfig(\n    baseline=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_BASELINE_V1',\n    source=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_SOURCE_V1',\n    timestamp_column='DATE',\n    id_columns=['MACHINE_ID'],\n    prediction_class_columns=['FAILURE_IN_1_DAY_PREDICTION'],\n    actual_class_columns=['FAILURE_IN_1_DAY']\n)\n\nmonitor_config = ModelMonitorConfig(\n    model_version=production_model,\n    model_function_name='predict',\n    background_compute_warehouse_name='AI_WH',\n    refresh_interval='1 minute',\n    aggregation_window='1 day'\n)\n\nmodel_monitor = my_model_registry.add_monitor(\n    name=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_MM_V1',\n    source_config=source_config,\n    model_monitor_config=monitor_config\n)"
    },
    {
      "cell_type": "markdown",
      "id": "588b7a8e-d2f0-431d-bb07-a1bebe68d5c6",
      "metadata": {
        "collapsed": false,
        "name": "SIMULATE_FUTURE_MODEL_PERFORMANCE",
        "codeCollapsed": true
      },
      "source": "# 11 - Simulate Future Data and Model Predictions"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01d4c95-b38a-4154-8747-aaca81d2aced",
      "metadata": {
        "language": "python",
        "name": "SIMULATE_FUTURE_MODEL_PERFORMANCE_1"
      },
      "outputs": [],
      "source": "#demo_functions.generate_machine_data(session, schema, start_date='2025-04-01', end_date='2025-10-31', mode='append')\ndemo_functions.generate_machine_data(session, schema, start_date='2025-04-01', end_date='2026-01-20', mode='append')\n\n# we manually refresh the feature store for demo purposes\nmy_feature_store.refresh_feature_view(lag_features_fv)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5568e27-cece-43fb-8e5f-49088c69cfba",
      "metadata": {
        "language": "python",
        "name": "SIMULATE_FUTURE_MODEL_PERFORMANCE_2"
      },
      "outputs": [],
      "source": "def create_feature_df(start_date, end_date, feature_store):\n    # Create spine dataframe\n    spine_df = (\n        session.table(f'{database}.{schema}.MACHINE_SENSORS')\n            .with_column('DATE', F.date_trunc('DAY','SENSOR_TIMESTAMP').cast('date'))\n            .filter(F.col('DATE').between(start_date, end_date))\n            .select('MACHINE_ID','DATE')\n            .distinct()\n            .order_by('MACHINE_ID','DATE')\n    )\n\n    # Retrieve features\n    feature_df = feature_store.retrieve_feature_values(\n        spine_df=spine_df,\n        features=[lag_features_fv],\n        spine_timestamp_col=\"DATE\"\n    )\n\n    return feature_df\n\n#feature_df = create_feature_df(start_date='2025-04-01', end_date='2025-10-31', feature_store=my_feature_store)\nfeature_df = create_feature_df(start_date='2025-04-01', end_date='2026-01-20', feature_store=my_feature_store)\ndisplay(feature_df.limit(10))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5569e57-256c-43ba-b598-72c6c3c761be",
      "metadata": {
        "language": "python",
        "name": "SIMULATE_FUTURE_MODEL_PERFORMANCE_3"
      },
      "outputs": [],
      "source": "# Score model\npredictions = production_model.run(feature_df, function_name='predict').cache_result()\n\n# Add actual machine failures\nmachine_failures = (\n    session.table(f'{database}.{schema}.MACHINE_FAILURES')\n        .with_column('DATE', F.date_add(F.col('DATE'), F.lit(-1)))\n        .rename({'FAILURE':'FAILURE_IN_1_DAY'})\n)\n\npredictions = predictions.join(machine_failures, how='left', on=['MACHINE_ID','DATE']).fillna(0, subset=['FAILURE_IN_1_DAY'])\n\n# Append predictions and actual to model monitor\npredictions.write.save_as_table(\n    f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_SOURCE_V1', \n    mode='append', \n    column_order='name'\n)"
    },
    {
      "cell_type": "markdown",
      "id": "195bb36b-ed84-444c-a7da-98e1f64b6d32",
      "metadata": {
        "collapsed": false,
        "name": "NEW_MODEL",
        "codeCollapsed": true
      },
      "source": "# 12 - Train a new model\n\n## 12.1 Generate Dataset"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f1e6622-a1fc-425b-b4dd-757fb1fdc633",
      "metadata": {
        "language": "python",
        "name": "NEW_MODEL_1"
      },
      "outputs": [],
      "source": "training_start_date = '2025-06-01'\ntraining_end_date = '2025-07-31'\n\ntraining_dataset_df = generate_training_dataset(session, my_feature_store, training_start_date, training_end_date)"
    },
    {
      "cell_type": "markdown",
      "id": "aa366c83-c716-49c6-8286-fd073f26f07b",
      "metadata": {
        "collapsed": false,
        "name": "NEW_MODEL_2",
        "codeCollapsed": true
      },
      "source": "## 12.2 Train Model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "925b7f5d-b98e-4e3f-8687-5b99ce196899",
      "metadata": {
        "language": "python",
        "name": "NEW_MODEL_3"
      },
      "outputs": [],
      "source": "train_dataset_df = training_dataset_df.filter(F.col('DATE').between('2025-06-01','2025-06-30'))\ntest_datatset_df = training_dataset_df.filter(F.col('DATE').between('2025-07-01','2025-07-31'))\n\ntraining_results = train_models(train_dataset_df, test_datatset_df, experiment_name='PREDICTIVE_MAINTENANCE_MODELS_V2')\n\n# Retrieve model results\nfeature_columns = training_results['feature_columns']\ntarget_column = training_results['target_column']\nxgb_model = training_results['xgboost']['model']\nmetrics = training_results['xgboost']['metrics']"
    },
    {
      "cell_type": "markdown",
      "id": "1b6897a7-c7ee-445d-9c23-38fb0f662967",
      "metadata": {
        "collapsed": false,
        "name": "NEW_MODEL_4",
        "codeCollapsed": true
      },
      "source": "## 12.3 Register Model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9a503e-9fbe-4c62-b1b1-d44bca7b9953",
      "metadata": {
        "language": "python",
        "name": "NEW_MODEL_5"
      },
      "outputs": [],
      "source": "# Register model\nregistered_model = my_model_registry.log_model(\n    xgb_model,\n    model_name=\"PREDICTIVE_MAINTENANCE_MODEL\",\n    version_name='V2',\n    metrics=metrics,\n    comment=\"Model trained using XGBoost to predict machine failures\",\n    conda_dependencies=['xgboost'],\n    signatures={'predict':signature},\n    sample_input_data=training_dataset_df.select(feature_columns).limit(100),\n    options={\"relax_version\": True, \"enable_explainability\": False},\n    target_platforms=['WAREHOUSE','SNOWPARK_CONTAINER_SERVICES']\n)"
    },
    {
      "cell_type": "markdown",
      "id": "da2ea326-d1f1-40f8-b04d-96801fd0d97a",
      "metadata": {
        "collapsed": false,
        "name": "NEW_MODEL_6",
        "codeCollapsed": true
      },
      "source": "## 12.4 Replace Production Model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c0f9c6-5685-4f57-a8f9-ce0ce4ee25cb",
      "metadata": {
        "language": "python",
        "name": "NEW_MODEL_7"
      },
      "outputs": [],
      "source": "# Unset current production model\nproduction_model.unset_alias('PRODUCTION')\n\n# Set alias for model\nregistered_model.set_alias('PRODUCTION')\n\n# Retrieve the production model in your pipelines like this\nproduction_model = my_model_registry.get_model('PREDICTIVE_MAINTENANCE_MODEL').version('PRODUCTION')\nproduction_model.show_metrics()"
    },
    {
      "cell_type": "markdown",
      "id": "0d811c0e-1e08-4e43-a375-2c8001b5db70",
      "metadata": {
        "collapsed": false,
        "name": "NEW_MODEL_8",
        "codeCollapsed": true
      },
      "source": "## 12.5 Create Model Monitor"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690dd8b4-0be3-42c9-83d3-d1f1221eb3ba",
      "metadata": {
        "language": "python",
        "name": "NEW_MODEL_9"
      },
      "outputs": [],
      "source": "# Generate baseline predictions\nbaseline_predictions = production_model.run(test_datatset_df, function_name='predict').cache_result()\nbaseline_predictions.write.save_as_table(f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_BASELINE_V2', mode='overwrite')\nbaseline_predictions.write.save_as_table(f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_SOURCE_V2', mode='overwrite')\n\n# Create model monitor\nsource_config = ModelMonitorSourceConfig(\n    baseline=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_BASELINE_V2',\n    source=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_SOURCE_V2',\n    timestamp_column='DATE',\n    id_columns=['MACHINE_ID'],\n    prediction_class_columns=['FAILURE_IN_1_DAY_PREDICTION'],\n    actual_class_columns=['FAILURE_IN_1_DAY']\n)\n\nmonitor_config = ModelMonitorConfig(\n    model_version=production_model,\n    model_function_name='predict',\n    background_compute_warehouse_name='AI_WH',\n    refresh_interval='1 minute',\n    aggregation_window='1 day'\n)\n\nmodel_monitor = my_model_registry.add_monitor(\n    name=f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_MM_V2',\n    source_config=source_config,\n    model_monitor_config=monitor_config\n)"
    },
    {
      "cell_type": "markdown",
      "id": "4e1f6e69-6e90-43fb-9838-def15efc2e99",
      "metadata": {
        "collapsed": false,
        "name": "NEW_MODEL_10",
        "codeCollapsed": true
      },
      "source": "## 12.6 Generate Predictions"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6e4165-ad72-44db-9e37-0ad70946deb4",
      "metadata": {
        "language": "python",
        "name": "NEW_MODEL_11"
      },
      "outputs": [],
      "source": "# Retrieve features\n#feature_df = create_feature_df(start_date='2025-08-01', end_date='2025-10-31', feature_store=my_feature_store)\nfeature_df = create_feature_df(start_date='2025-08-01', end_date='2026-01-20', feature_store=my_feature_store)\n\n# Score model\npredictions = production_model.run(feature_df, function_name='predict').cache_result()\n\n# Add actual machine failures\nmachine_failures = (\n    session.table(f'{database}.{schema}.MACHINE_FAILURES')\n        .with_column('DATE', F.date_add(F.col('DATE'), F.lit(-1)))\n        .rename({'FAILURE':'FAILURE_IN_1_DAY'})\n)\n\npredictions = predictions.join(machine_failures, how='left', on=['MACHINE_ID','DATE']).fillna(0, subset=['FAILURE_IN_1_DAY'])\n\n# Append predictions and actuals to model monitor\npredictions.write.save_as_table(\n    f'{database}.{schema}_MODEL_REGISTRY.PREDICTIVE_MAINTENANCE_MODEL_SOURCE_V2', \n    mode='append', \n    column_order='name'\n)"
    },
    {
      "cell_type": "markdown",
      "id": "7b7e4782-127a-4978-823b-fe648971068b",
      "metadata": {
        "collapsed": false,
        "name": "SPCS_SERVICE_1",
        "codeCollapsed": true
      },
      "source": "# 13 - Deploy Model as Inference Service in SPCS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a58365e-6180-42fe-8bdb-7e27b0724799",
      "metadata": {
        "language": "python",
        "name": "SPCS_SERVICE_2"
      },
      "outputs": [],
      "source": "# Create Inference Service\nregistered_model.create_service(\n    service_name=\"my_pred_maintenance_prediction_service\",\n    service_compute_pool=\"SYSTEM_COMPUTE_POOL_CPU\",\n    ingress_enabled=True,\n    gpu_requests=None\n)"
    },
    {
      "cell_type": "markdown",
      "id": "10a4666a-57b3-4e30-bf78-8fae85a38d27",
      "metadata": {
        "collapsed": false,
        "name": "CALL_MODEL",
        "codeCollapsed": true
      },
      "source": "# 14 - Call Model via Python and REST-API"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f494c1f4-1c55-4c1f-9c84-6dd5aabecdab",
      "metadata": {
        "language": "python",
        "name": "CALL_MODEL_1"
      },
      "outputs": [],
      "source": "# Call the service in Python\nservice_prediction = registered_model.run(\n    feature_df,\n    function_name=\"predict\",\n    service_name=\"my_pred_maintenance_prediction_service\"\n)\n\ndisplay(service_prediction.limit(10))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283c938c-378b-4bed-a89a-105a163b3629",
      "metadata": {
        "language": "python",
        "name": "CALL_MODEL_2"
      },
      "outputs": [],
      "source": "endpoint = session.sql(\"SHOW ENDPOINTS IN SERVICE my_pred_maintenance_prediction_service\").collect()\npd.DataFrame(endpoint)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e539a987-3cca-4125-b5b8-a3b578707fa5",
      "metadata": {
        "language": "python",
        "name": "CALL_MODEL_3"
      },
      "outputs": [],
      "source": "import requests\n\n# Get Programmatic Access Token\npat_token = session.sql(\"ALTER USER ADD PROGRAMMATIC ACCESS TOKEN demo_token;\").collect()\npat_token = pat_token[0]['token_secret']\n\n# Define URL and headers\nURL = f\"https://{endpoint[0]['ingress_url']}/predict\"\nheaders = {\"Authorization\": f'Snowflake Token=\"{pat_token}\"'}\n\n# Prepare data to be sent\npayload_data = {\n    'data': []\n}\n\n# normal condition\npayload_data['data'].append([0, 1,1,1,1,1,1,1,1,1])\n\n# failure condition\npayload_data['data'].append([\n    1, \n    2.051990032196045,\n    2.684382438659668,\n    2.0562567710876465,\n    1.9639095067977905,\n    1.320631742477417,\n    1.7546310424804688,\n    1.9142093658447266,\n    1.3605632781982422,\n    1.601170897483825\n])\n\nprint('Input Data:')\nprint(json.dumps(payload_data, indent=2))\n\nprint('Output:')\nr = requests.post(URL, json=payload_data, headers=headers)\nprint(json.dumps(r.json(), indent=2))\n\n# Remove PAT\n_ = session.sql(\"ALTER USER REMOVE PROGRAMMATIC ACCESS TOKEN demo_token;\").collect()"
    },
    {
      "id": "769de75d-73b1-49db-a73b-69faf60f2a56",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "_ = session.sql(\"ALTER USER REMOVE PROGRAMMATIC ACCESS TOKEN demo_token;\").collect()",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "authorEmail": "michael.gorkow@snowflake.com",
      "authorId": "61864603178",
      "authorName": "ADMIN",
      "lastEditTime": 1764035648785,
      "notebookId": "tbijml4u4hbtqudqemlm",
      "sessionId": "8ba307b7-1f7d-4107-9395-39cb01f635b1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}